{
  "hash": "3b224002e456b44fdbe7ab76b54824bb",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Bisection Method'\nauthor: 'Nathan Lunceford'\nformat:\n  html:\n    self-contained: true\n    page-layout: full\n    toc: true\n    toc-depth: 1\n    toc-location: right\n    number-sections: false\n    html-math-method: katex\n    embed-resources: true\n    code-fold: true\n    code-summary: 'Show the code'\n    code-overflow: wrap\n    code-copy: hover\n    code-tools:\n      source: false\n      toggle: true\n      caption: See code\nengine: jupyter\npreview:\n  port: 3000\n  browser: true\n  watch-inputs: true\n  navigate: true\n---\n\n\n**Bisection Method** is one of the simplest and most reliable numerical methods for finding a root of a continuous function $f(x) = 0$ over a closed interval $[a, b]$. The method works by repeatedly bisecting the interval and then selecting the subinterval in which the function changes sign, ensuring that a root lies within that subinterval.\n\n## **The Bisection Method Formula**\n\nThe Bisection Method requires that the function $f(x)$ be continuous over the interval $[a, b]$, and that the function has opposite signs at the endpoints $a$ and $b$, i.e., $f(a) \\cdot f(b) < 0$. This guarantees that there is at least one root in the interval by the **Intermediate Value Theorem**.\n\nThe basic idea of the method is to repeatedly bisect the interval and check the sign of $f(x)$ at the midpoint to determine the subinterval containing the root.\n\n### **Algorithm**\n\n1. **Initial Guess**: Choose an interval $[a_0, b_0]$ such that $f(a_0) \\cdot f(b_0) < 0$.\n2. **Midpoint Calculation**: Compute the midpoint $c_k = \\frac{a_k + b_k}{2}$ of the interval $[a_k, b_k]$.\n3. **Check the Sign**: Evaluate $f(c_k)$.\n   - If $f(c_k) = 0$, then $c_k$ is the root.\n   - If $f(a_k) \\cdot f(c_k) < 0$, set $b_{k+1} = c_k$, and the root lies in $[a_k, c_k]$.\n   - If $f(c_k) \\cdot f(b_k) < 0$, set $a_{k+1} = c_k$, and the root lies in $[c_k, b_k]$.\n4. **Repeat**: Continue bisecting the interval until the length of the interval is smaller than a specified tolerance $\\epsilon$, or until $|f(c_k)| < \\epsilon$.\n\nThe approximate root will be:\n\n$$\nx^* = \\frac{a_k + b_k}{2}\n$$\n\n### **Convergence**\n\nThe Bisection Method converges **linearly**. The length of the interval halves at each iteration, ensuring that the method always converges to a solution (if one exists) within the interval.\n\nThe number of iterations $n$ required to achieve an accuracy of $\\epsilon$ can be estimated by:\n\n$$\nn \\geq \\frac{\\log \\left( \\frac{b_0 - a_0}{\\epsilon} \\right)}{\\log 2}\n$$\n\n### **Example**\n\nLet’s solve the equation $f(x) = x^3 - x - 2 = 0$ in the interval $[1, 2]$.\n\n1. **Initial Interval**:  \n   $f(1) = 1^3 - 1 - 2 = -2$  \n   $f(2) = 2^3 - 2 - 2 = 4$  \n   Since $f(1) \\cdot f(2) < 0$, there is a root in $[1, 2]$.\n\n2. **First Iteration**:  \n   Midpoint: $c_1 = \\frac{1 + 2}{2} = 1.5$  \n   $f(1.5) = 1.5^3 - 1.5 - 2 = -0.125$  \n   Since $f(1) \\cdot f(1.5) < 0$, the root lies in $[1, 1.5]$.\n\n3. **Second Iteration**:  \n   Midpoint: $c_2 = \\frac{1 + 1.5}{2} = 1.25$  \n   $f(1.25) = 1.25^3 - 1.25 - 2 = -1.796875$  \n   Since $f(1) \\cdot f(1.25) < 0$, the root lies in $[1, 1.25]$.\n\n4. **Further Iterations**:  \n   Repeat the process until the interval width is smaller than the desired tolerance $\\epsilon$.\n\n### **General Properties of the Bisection Method**\n\n1. **Guaranteed Convergence**: The method is guaranteed to converge to a root if $f(a) \\cdot f(b) < 0$ and $f(x)$ is continuous on $[a, b]$.\n\n2. **Rate of Convergence**: The Bisection Method has linear convergence, meaning the error decreases by a constant factor with each iteration. This makes the method slower than other methods like **Newton’s Method**, but much more reliable.\n\n3. **Robustness**: The method is very robust as it does not require the derivative of the function and is insensitive to the initial guesses, provided the condition $f(a) \\cdot f(b) < 0$ holds.\n\n### **Applications of the Bisection Method**\n\n- **Root Finding**: The Bisection Method is used in various fields, including physics, engineering, and mathematics, to find roots of non-linear equations.\n- **Modeling and Simulation**: It is used when precise solutions are needed and the function is known to be continuous over the interval.\n- **Initial Root Estimates**: The Bisection Method is often used to find a good initial approximation for more efficient methods like **Newton’s Method** or the **Secant Method**.\n\n### **Advantages of the Bisection Method**\n\n1. **Guaranteed Convergence**: The method always converges if the initial interval contains a root.\n2. **No Derivatives Needed**: Unlike Newton’s Method, the Bisection Method does not require the computation of derivatives.\n3. **Simplicity**: The method is easy to understand and implement.\n\n### **Limitations of the Bisection Method**\n\n1. **Slow Convergence**: The method converges linearly, which makes it slower compared to methods like Newton’s Method, which has quadratic convergence.\n2. **Only One Root**: The Bisection Method only finds one root in the interval. If multiple roots exist, it cannot find them all without running the method on different intervals.\n\n3. **Initial Interval Requirement**: The method requires an initial interval $[a, b]$ where the function changes sign, which may not always be easy to determine.\n\n### **Conclusion**\n\nThe Bisection Method is a reliable and simple method for finding roots of continuous functions, especially when no derivative information is available. While slower than other root-finding algorithms, its guaranteed convergence and robustness make it a valuable tool in numerical analysis.\n\n",
    "supporting": [
      "bisection-method_files"
    ],
    "filters": [],
    "includes": {}
  }
}