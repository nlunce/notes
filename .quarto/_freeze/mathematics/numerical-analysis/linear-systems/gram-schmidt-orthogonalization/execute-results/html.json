{
  "hash": "67f96b952a644346fa5bb2540b1d741d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Gram-Schmidt Orthogonalization'\nauthor: 'Nathan Lunceford'\nformat:\n  html:\n    self-contained: true\n    page-layout: full\n    toc: true\n    toc-depth: 1\n    toc-location: right\n    number-sections: false\n    html-math-method: katex\n    embed-resources: true\n    code-fold: true\n    code-summary: 'Show the code'\n    code-overflow: wrap\n    code-copy: hover\n    code-tools:\n      source: false\n      toggle: true\n      caption: See code\nengine: jupyter\npreview:\n  port: 3000\n  browser: true\n  watch-inputs: true\n  navigate: true\n---\n\n\n## Overview\n\nThe Gram-Schmidt Orthogonalization process is a fundamental technique in linear algebra for transforming a set of linearly independent vectors into an orthogonal (or orthonormal) set that spans the same subspace. This method is widely used in applications such as QR factorization, solving [**least squares problems**](./least-squares.html), and numerical linear algebra. This note explores the definition, properties, computation, and applications of the Gram-Schmidt process.\n\n## Definition and Process\n\nGiven a set of linearly independent vectors $A_1, A_2, \\dots, A_n$, the Gram-Schmidt process produces an orthogonal (or orthonormal) set of vectors $q_1, q_2, \\dots, q_n$ such that:\n\n1. Each vector $q_i$ is orthogonal to the previous vectors $q_1, q_2, \\dots, q_{i-1}$.\n2. The span of $q_1, q_2, \\dots, q_n$ is the same as the span of $A_1, A_2, \\dots, A_n$.\n\nThis orthogonal set can also be normalized to create an orthonormal basis.\n\n## Steps of the Gram-Schmidt Process\n\nThe Gram-Schmidt process involves the following steps:\n\n1. **Initialize with the First Vector**: Set $q_1$ as the normalized version of $A_1$:\n\n   $$\n   q_1 = \\frac{A_1}{\\|A_1\\|}\n   $$\n\n2. **Compute Subsequent Vectors**: For each vector $A_i$, construct a new vector $u_i$ by subtracting components that align with previously computed $q$-vectors. Normalize $u_i$ to obtain $q_i$:\n   - Define the non-normalized vector $u_i$:\n     $$\n     u_i = A_i - \\sum_{j=1}^{i-1} (q_j \\cdot A_i) \\, q_j\n     $$\n   - Normalize $u_i$ to obtain $q_i$:\n     $$\n     q_i = \\frac{u_i}{\\|u_i\\|}\n     $$\n\nEach vector $q_i$ is thus orthogonal to the preceding $q$-vectors and has unit length if normalized.\n\n## Example\n\nGiven vectors $A_1$ and $A_2$, the Gram-Schmidt process works as follows:\n\n1. **Calculate $q_1$**:\n\n   $$\n   q_1 = \\frac{A_1}{\\|A_1\\|}\n   $$\n\n2. **Calculate $q_2$**:\n   - First, remove the component of $A_2$ in the direction of $q_1$ to obtain $u_2$:\n     $$\n     u_2 = A_2 - (q_1 \\cdot A_2) q_1\n     $$\n   - Then, normalize $u_2$ to get $q_2$:\n     $$\n     q_2 = \\frac{u_2}{\\|u_2\\|}\n     $$\n\n## Properties of Gram-Schmidt Orthogonalization\n\n- **Orthogonality**: Each vector $q_i$ is orthogonal to all previously generated vectors $q_1, \\dots, q_{i-1}$.\n- **Span Preservation**: The set $\\{q_1, q_2, \\dots, q_n\\}$ spans the same subspace as the original set $\\{A_1, A_2, \\dots, A_n\\}$.\n- **Orthonormal Basis**: By normalizing each $u_i$ to get $q_i$, the process yields an orthonormal basis for the subspace.\n\n## Applications of Gram-Schmidt Orthogonalization\n\nGram-Schmidt orthogonalization is widely applied in various fields due to its utility in creating orthogonal bases:\n\n- **QR Factorization**: Used to decompose a matrix into an orthogonal matrix $Q$ and an upper triangular matrix $R$.\n- [**Least Squares Problems**](./least-squares.html): Assists in minimizing the error in fitting data to a model by creating orthogonal projections.\n- **Signal Processing and Data Compression**: Forms the foundation for methods that reduce redundancy by representing data in orthogonal bases.\n- **Machine Learning and Statistics**: Simplifies computations by projecting data onto orthogonal components.\n\n## Example Problem\n\n**Problem:** Given the vectors\n\n$$\nA_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}, \\quad A_2 = \\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\end{pmatrix}\n$$\n\n1. **Use Gram-Schmidt to find orthogonal vectors $q_1$ and $q_2$**.\n2. **Normalize $q_1$ and $q_2$ to form an orthonormal basis.**\n\n### Solution Steps\n\n1. **Compute $q_1$** by normalizing $A_1$.\n2. **Calculate $u_2$** by removing the component of $A_2$ in the direction of $q_1$.\n3. **Normalize $u_2$ to obtain $q_2$**.\n\n## Conclusion\n\nThe Gram-Schmidt process is a valuable tool in linear algebra for constructing orthogonal (or orthonormal) bases. By transforming a set of linearly independent vectors, it simplifies many matrix operations and lays the groundwork for QR factorization, data projections, and error minimization in least squares problems.\n\n",
    "supporting": [
      "gram-schmidt-orthogonalization_files"
    ],
    "filters": [],
    "includes": {}
  }
}