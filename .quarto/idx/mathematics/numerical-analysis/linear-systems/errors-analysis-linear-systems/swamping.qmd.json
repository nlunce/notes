{"title":"Understanding Swamping in Numerical Computations","markdown":{"yaml":{"title":"Understanding Swamping in Numerical Computations","author":"Nathan Lunceford","format":{"html":{"self-contained":true,"page-layout":"full","toc":true,"toc-depth":3,"toc-location":"right","number-sections":false,"html-math-method":"katex","embed-resources":true,"code-fold":true,"code-summary":"Show Code","code-overflow":"wrap","code-copy":"hover","code-tools":{"source":false,"toggle":true,"caption":"See code"}}},"engine":"jupyter","preview":{"port":3000,"browser":true,"watch-inputs":true,"navigate":true}},"headingText":"**Overview**","containsRefs":false,"markdown":"\n\n\nIn the realm of numerical computations, precision and accuracy are paramount. However, various phenomena can undermine these qualities, leading to erroneous results. One such phenomenon is **swamping**, a term that describes the masking or overwhelming of smaller errors by larger ones, making it difficult to detect or mitigate the underlying issues. Understanding swamping is essential for developing robust numerical algorithms and ensuring the reliability of computational results.\n\n## **What is Swamping?**\n\n**Swamping** refers to the scenario where smaller errors or perturbations in a numerical computation are obscured or dominated by larger errors. This can occur in various contexts, such as solving linear systems, eigenvalue computations, or iterative algorithms. When swamping happens, it becomes challenging to identify and correct minor inaccuracies, potentially leading to significant deviations in the final outcome.\n\nMathematically, consider a computation where multiple sources of errors are present. If one error component is significantly larger than others, it can overshadow the smaller ones, effectively \"swamping\" them. This makes it difficult to assess the cumulative effect of all errors accurately.\n\n## **Causes of Swamping**\n\nSwamping can arise from several factors in numerical computations:\n\n1. **Finite Precision Arithmetic:**\n\n   - **Round-Off Errors:** In floating-point computations, numbers are represented with limited precision. Repeated arithmetic operations can accumulate round-off errors, where smaller errors become overshadowed by larger ones.\n   - **Cancellation Errors:** Subtracting nearly equal numbers can result in significant loss of precision, amplifying existing errors.\n\n2. **Ill-Conditioned Systems:**\n\n   - Systems with a high [**condition number**](./condition-number-matrix.html) are sensitive to perturbations. Small errors in input data or intermediate computations can lead to large errors in the solution, causing swamping.\n\n3. **Algorithmic Instabilities:**\n\n   - Certain numerical algorithms may amplify specific error components due to their inherent design, leading to swamping of other errors.\n\n4. **Data Noise:**\n   - In data-driven computations, high levels of noise can mask underlying signals, making it difficult to detect subtle patterns or trends.\n\n## **Implications of Swamping**\n\nSwamping has several critical implications for numerical computations:\n\n- **Reduced Accuracy:** The dominance of larger errors can significantly reduce the overall accuracy of the computation.\n- **Error Propagation:** Swamping can lead to uncontrolled error propagation, where inaccuracies at one stage of computation affect subsequent stages.\n- **Algorithm Reliability:** Algorithms susceptible to swamping may produce unreliable results, undermining their applicability in sensitive applications.\n- **Difficulty in Debugging:** Identifying and isolating the sources of errors becomes challenging when swamping occurs, complicating the debugging process.\n\n## **Detecting and Mitigating Swamping**\n\nEffective detection and mitigation strategies are essential to manage swamping in numerical computations:\n\n### 1. **Error Analysis:**\n\n- **Relative and Absolute Errors:** Monitor both relative and absolute errors to identify when smaller errors are being overshadowed.\n- **Residual Analysis:** In solving linear systems, analyze the residual $\\mathbf{r} = \\mathbf{b} - A\\mathbf{x}$ to assess the accuracy of the solution.\n\n### 2. **Condition Number Assessment:**\n\n- **Compute Condition Numbers:** Evaluate the condition number of matrices involved using appropriate norms (e.g., [**Infinity Norm**](../norms/infinity-vector-norm.html)) to gauge sensitivity.\n- **Well-Conditioned vs. Ill-Conditioned:** Prefer algorithms and formulations that minimize the condition number to reduce susceptibility to swamping.\n\n### 3. **Algorithm Selection and Improvement:**\n\n- **Stable Algorithms:** Choose numerical methods known for their stability and resistance to error amplification (e.g., using QR decomposition over Gaussian elimination in certain cases).\n- **Pivoting Techniques:** Implement pivoting strategies in matrix factorizations to enhance numerical stability.\n\n### 4. **Precision Management:**\n\n- **Higher Precision Arithmetic:** Utilize higher precision data types (e.g., double-precision instead of single-precision) to minimize round-off and cancellation errors.\n- **Adaptive Precision:** Dynamically adjust the precision based on the sensitivity of the computation stages.\n\n### 5. **Regularization Techniques:**\n\n- **Tikhonov Regularization:** Introduce regularization terms to stabilize solutions, especially in ill-posed problems.\n- **Noise Filtering:** Apply filtering techniques to data to reduce noise levels and prevent swamping of subtle signals.\n\n## **A Practical Example**\n\nTo illustrate swamping, let's consider the problem of solving a linear system using Gaussian elimination without pivoting, which can be susceptible to error amplification in ill-conditioned systems.\n\n### **The Problem Setup**\n\nConsider the system:\n\n$$\nA\\mathbf{x} = \\mathbf{b}\n$$\n\nWhere:\n\n$$\nA = \\begin{bmatrix}\n1 & 1 \\\\\n1 & 1.0001 \\\\\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix}\n2 \\\\\n2.0001 \\\\\n\\end{bmatrix}\n$$\n\nThe true solution is:\n\n$$\n\\mathbf{x} = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n\\end{bmatrix}\n$$\n\n### **Step 1: Compute the Condition Number $\\kappa_\\infty(A)$**\n\nUsing the **Infinity Norm**:\n\n$$\n\\|A\\|_\\infty = \\max \\left\\{ |1| + |1|, \\ |1| + |1.0001| \\right\\} = \\max \\{2, 2.0001\\} = 2.0001\n$$\n\nCompute $A^{-1}$:\n\n$$\n\\det(A) = (1)(1.0001) - (1)(1) = 0.0001\n$$\n\n$$\nA^{-1} = \\frac{1}{0.0001} \\begin{bmatrix}\n1.0001 & -1 \\\\\n-1 & 1 \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n10001 & -10000 \\\\\n-10000 & 10000 \\\\\n\\end{bmatrix}\n$$\n\n$$\n\\|A^{-1}\\|_\\infty = \\max \\left\\{ |10001| + |-10000|, \\ |-10000| + |10000| \\right\\} = \\max \\{20001, 20000\\} = 20001\n$$\n\nThus,\n\n$$\n\\kappa_\\infty(A) = \\|A\\|_\\infty \\cdot \\|A^{-1}\\|_\\infty = 2.0001 \\times 20001 \\approx 40004\n$$\n\nA condition number of approximately **40004** indicates that the matrix $A$ is **ill-conditioned**, making the system highly sensitive to perturbations.\n\n### **Step 2: Solve the System Using Gaussian Elimination Without Pivoting**\n\nPerforming Gaussian elimination:\n\n1. **First Pivot:** The element $a_{11} = 1$ is used to eliminate the first entry in the second row.\n\n2. **Elimination Step:**\n\n   $\\text{Multiplier} = \\frac{a_{21}}{a_{11}} = \\frac{1}{1} = 1$\n\n   Update the second row:\n\n   $a_{22}' = a_{22} - \\text{Multiplier} \\times a_{12} = 1.0001 - 1 \\times 1 = 0.0001$\n\n   $b_2' = b_2 - \\text{Multiplier} \\times b_1 = 2.0001 - 1 \\times 2 = 0.0001$\n\n3. **Back Substitution:**\n\n   $x_2 = \\frac{b_2'}{a_{22}'} = \\frac{0.0001}{0.0001} = 1$\n\n   $x_1 = \\frac{b_1 - a_{12}x_2}{a_{11}} = \\frac{2 - 1 \\times 1}{1} = 1$\n\nThe computed solution is $\\mathbf{x} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, which matches the true solution. However, this accuracy is contingent on the precision of computations and the absence of rounding errors.\n\n### **Step 3: Introduce Perturbations to Simulate Swamping**\n\nNow, let's introduce a more **realistic perturbation** that simulates how a computer might **round off** numbers during computations.\n\n#### **Analogy: Computer Rounding Leading to Swamping**\n\nComputers represent numbers with finite precision, typically using floating-point arithmetic. Suppose during calculations, the computer rounds the number **2.0001** to **2** due to limited precision. This seemingly minor adjustment can have a **drastic impact** on the solution.\n\n- **Perturbed Equation 2:**  \n  $x + 1.0001y = 2$  \n  _(Notice the right-hand side changed from 2.0001 to 2 due to rounding)_\n\nThis small change is akin to a computer rounding **2.0001** down to **2**, illustrating how precision limitations can lead to significant deviations.\n\n### **Step 4: Solving the Perturbed System**\n\nWith the perturbed equation, the system becomes:\n\n$$\nA\\mathbf{x} = \\mathbf{b}\n$$\n\nWhere:\n\n$$\n\\mathbf{b} = \\begin{bmatrix}\n2 \\\\\n2 \\\\\n\\end{bmatrix}\n$$\n\nReapplying Gaussian elimination:\n\n1. **Elimination Step:**\n\n   $\\text{Multiplier} = \\frac{a_{21}}{a_{11}} = \\frac{1}{1} = 1$\n\n   Update the second row:\n\n   $a_{22}' = a_{22} - \\text{Multiplier} \\times a_{12} = 1.0001 - 1 \\times 1 = 0.0001$\n\n   $b_2' = b_2 - \\text{Multiplier} \\times b_1 = 2 - 1 \\times 2 = 0$\n\n2. **Back Substitution:**\n\n   $x_2 = \\frac{b_2'}{a_{22}'} = \\frac{0}{0.0001} = 0$\n\n   $x_1 = \\frac{b_1 - a_{12}x_2}{a_{11}} = \\frac{2 - 1 \\times 0}{1} = 2$\n\nThe computed solution is $\\mathbf{x} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$, which **deviates significantly** from the true solution $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\n### **Step 5: Analyzing the Impact**\n\n- **Original Solution:** $(x, y) = (1, 1)$\n- **After Rounding Error:** $(x, y) = (2, 0)$\n\n**Observation:**  \nA **minuscule rounding error** in the constant term of the second equation (from 2.0001 to 2) caused the solution to shift dramatically from $(1, 1)$ to $(2, 0)$.\n\n### **Step 6: Interpretation**\n\nThe small perturbation in $\\mathbf{b}$ led to a substantial error in the solution, illustrating how swamping can occur in ill-conditioned systems. The large condition number amplified the minor change in $\\mathbf{b}$, resulting in a significant deviation in $\\mathbf{x}$.\n","srcMarkdownNoYaml":"\n\n## **Overview**\n\nIn the realm of numerical computations, precision and accuracy are paramount. However, various phenomena can undermine these qualities, leading to erroneous results. One such phenomenon is **swamping**, a term that describes the masking or overwhelming of smaller errors by larger ones, making it difficult to detect or mitigate the underlying issues. Understanding swamping is essential for developing robust numerical algorithms and ensuring the reliability of computational results.\n\n## **What is Swamping?**\n\n**Swamping** refers to the scenario where smaller errors or perturbations in a numerical computation are obscured or dominated by larger errors. This can occur in various contexts, such as solving linear systems, eigenvalue computations, or iterative algorithms. When swamping happens, it becomes challenging to identify and correct minor inaccuracies, potentially leading to significant deviations in the final outcome.\n\nMathematically, consider a computation where multiple sources of errors are present. If one error component is significantly larger than others, it can overshadow the smaller ones, effectively \"swamping\" them. This makes it difficult to assess the cumulative effect of all errors accurately.\n\n## **Causes of Swamping**\n\nSwamping can arise from several factors in numerical computations:\n\n1. **Finite Precision Arithmetic:**\n\n   - **Round-Off Errors:** In floating-point computations, numbers are represented with limited precision. Repeated arithmetic operations can accumulate round-off errors, where smaller errors become overshadowed by larger ones.\n   - **Cancellation Errors:** Subtracting nearly equal numbers can result in significant loss of precision, amplifying existing errors.\n\n2. **Ill-Conditioned Systems:**\n\n   - Systems with a high [**condition number**](./condition-number-matrix.html) are sensitive to perturbations. Small errors in input data or intermediate computations can lead to large errors in the solution, causing swamping.\n\n3. **Algorithmic Instabilities:**\n\n   - Certain numerical algorithms may amplify specific error components due to their inherent design, leading to swamping of other errors.\n\n4. **Data Noise:**\n   - In data-driven computations, high levels of noise can mask underlying signals, making it difficult to detect subtle patterns or trends.\n\n## **Implications of Swamping**\n\nSwamping has several critical implications for numerical computations:\n\n- **Reduced Accuracy:** The dominance of larger errors can significantly reduce the overall accuracy of the computation.\n- **Error Propagation:** Swamping can lead to uncontrolled error propagation, where inaccuracies at one stage of computation affect subsequent stages.\n- **Algorithm Reliability:** Algorithms susceptible to swamping may produce unreliable results, undermining their applicability in sensitive applications.\n- **Difficulty in Debugging:** Identifying and isolating the sources of errors becomes challenging when swamping occurs, complicating the debugging process.\n\n## **Detecting and Mitigating Swamping**\n\nEffective detection and mitigation strategies are essential to manage swamping in numerical computations:\n\n### 1. **Error Analysis:**\n\n- **Relative and Absolute Errors:** Monitor both relative and absolute errors to identify when smaller errors are being overshadowed.\n- **Residual Analysis:** In solving linear systems, analyze the residual $\\mathbf{r} = \\mathbf{b} - A\\mathbf{x}$ to assess the accuracy of the solution.\n\n### 2. **Condition Number Assessment:**\n\n- **Compute Condition Numbers:** Evaluate the condition number of matrices involved using appropriate norms (e.g., [**Infinity Norm**](../norms/infinity-vector-norm.html)) to gauge sensitivity.\n- **Well-Conditioned vs. Ill-Conditioned:** Prefer algorithms and formulations that minimize the condition number to reduce susceptibility to swamping.\n\n### 3. **Algorithm Selection and Improvement:**\n\n- **Stable Algorithms:** Choose numerical methods known for their stability and resistance to error amplification (e.g., using QR decomposition over Gaussian elimination in certain cases).\n- **Pivoting Techniques:** Implement pivoting strategies in matrix factorizations to enhance numerical stability.\n\n### 4. **Precision Management:**\n\n- **Higher Precision Arithmetic:** Utilize higher precision data types (e.g., double-precision instead of single-precision) to minimize round-off and cancellation errors.\n- **Adaptive Precision:** Dynamically adjust the precision based on the sensitivity of the computation stages.\n\n### 5. **Regularization Techniques:**\n\n- **Tikhonov Regularization:** Introduce regularization terms to stabilize solutions, especially in ill-posed problems.\n- **Noise Filtering:** Apply filtering techniques to data to reduce noise levels and prevent swamping of subtle signals.\n\n## **A Practical Example**\n\nTo illustrate swamping, let's consider the problem of solving a linear system using Gaussian elimination without pivoting, which can be susceptible to error amplification in ill-conditioned systems.\n\n### **The Problem Setup**\n\nConsider the system:\n\n$$\nA\\mathbf{x} = \\mathbf{b}\n$$\n\nWhere:\n\n$$\nA = \\begin{bmatrix}\n1 & 1 \\\\\n1 & 1.0001 \\\\\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix}\n2 \\\\\n2.0001 \\\\\n\\end{bmatrix}\n$$\n\nThe true solution is:\n\n$$\n\\mathbf{x} = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n\\end{bmatrix}\n$$\n\n### **Step 1: Compute the Condition Number $\\kappa_\\infty(A)$**\n\nUsing the **Infinity Norm**:\n\n$$\n\\|A\\|_\\infty = \\max \\left\\{ |1| + |1|, \\ |1| + |1.0001| \\right\\} = \\max \\{2, 2.0001\\} = 2.0001\n$$\n\nCompute $A^{-1}$:\n\n$$\n\\det(A) = (1)(1.0001) - (1)(1) = 0.0001\n$$\n\n$$\nA^{-1} = \\frac{1}{0.0001} \\begin{bmatrix}\n1.0001 & -1 \\\\\n-1 & 1 \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n10001 & -10000 \\\\\n-10000 & 10000 \\\\\n\\end{bmatrix}\n$$\n\n$$\n\\|A^{-1}\\|_\\infty = \\max \\left\\{ |10001| + |-10000|, \\ |-10000| + |10000| \\right\\} = \\max \\{20001, 20000\\} = 20001\n$$\n\nThus,\n\n$$\n\\kappa_\\infty(A) = \\|A\\|_\\infty \\cdot \\|A^{-1}\\|_\\infty = 2.0001 \\times 20001 \\approx 40004\n$$\n\nA condition number of approximately **40004** indicates that the matrix $A$ is **ill-conditioned**, making the system highly sensitive to perturbations.\n\n### **Step 2: Solve the System Using Gaussian Elimination Without Pivoting**\n\nPerforming Gaussian elimination:\n\n1. **First Pivot:** The element $a_{11} = 1$ is used to eliminate the first entry in the second row.\n\n2. **Elimination Step:**\n\n   $\\text{Multiplier} = \\frac{a_{21}}{a_{11}} = \\frac{1}{1} = 1$\n\n   Update the second row:\n\n   $a_{22}' = a_{22} - \\text{Multiplier} \\times a_{12} = 1.0001 - 1 \\times 1 = 0.0001$\n\n   $b_2' = b_2 - \\text{Multiplier} \\times b_1 = 2.0001 - 1 \\times 2 = 0.0001$\n\n3. **Back Substitution:**\n\n   $x_2 = \\frac{b_2'}{a_{22}'} = \\frac{0.0001}{0.0001} = 1$\n\n   $x_1 = \\frac{b_1 - a_{12}x_2}{a_{11}} = \\frac{2 - 1 \\times 1}{1} = 1$\n\nThe computed solution is $\\mathbf{x} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, which matches the true solution. However, this accuracy is contingent on the precision of computations and the absence of rounding errors.\n\n### **Step 3: Introduce Perturbations to Simulate Swamping**\n\nNow, let's introduce a more **realistic perturbation** that simulates how a computer might **round off** numbers during computations.\n\n#### **Analogy: Computer Rounding Leading to Swamping**\n\nComputers represent numbers with finite precision, typically using floating-point arithmetic. Suppose during calculations, the computer rounds the number **2.0001** to **2** due to limited precision. This seemingly minor adjustment can have a **drastic impact** on the solution.\n\n- **Perturbed Equation 2:**  \n  $x + 1.0001y = 2$  \n  _(Notice the right-hand side changed from 2.0001 to 2 due to rounding)_\n\nThis small change is akin to a computer rounding **2.0001** down to **2**, illustrating how precision limitations can lead to significant deviations.\n\n### **Step 4: Solving the Perturbed System**\n\nWith the perturbed equation, the system becomes:\n\n$$\nA\\mathbf{x} = \\mathbf{b}\n$$\n\nWhere:\n\n$$\n\\mathbf{b} = \\begin{bmatrix}\n2 \\\\\n2 \\\\\n\\end{bmatrix}\n$$\n\nReapplying Gaussian elimination:\n\n1. **Elimination Step:**\n\n   $\\text{Multiplier} = \\frac{a_{21}}{a_{11}} = \\frac{1}{1} = 1$\n\n   Update the second row:\n\n   $a_{22}' = a_{22} - \\text{Multiplier} \\times a_{12} = 1.0001 - 1 \\times 1 = 0.0001$\n\n   $b_2' = b_2 - \\text{Multiplier} \\times b_1 = 2 - 1 \\times 2 = 0$\n\n2. **Back Substitution:**\n\n   $x_2 = \\frac{b_2'}{a_{22}'} = \\frac{0}{0.0001} = 0$\n\n   $x_1 = \\frac{b_1 - a_{12}x_2}{a_{11}} = \\frac{2 - 1 \\times 0}{1} = 2$\n\nThe computed solution is $\\mathbf{x} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$, which **deviates significantly** from the true solution $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\n### **Step 5: Analyzing the Impact**\n\n- **Original Solution:** $(x, y) = (1, 1)$\n- **After Rounding Error:** $(x, y) = (2, 0)$\n\n**Observation:**  \nA **minuscule rounding error** in the constant term of the second equation (from 2.0001 to 2) caused the solution to shift dramatically from $(1, 1)$ to $(2, 0)$.\n\n### **Step 6: Interpretation**\n\nThe small perturbation in $\\mathbf{b}$ led to a substantial error in the solution, illustrating how swamping can occur in ill-conditioned systems. The large condition number amplified the minor change in $\\mathbf{b}$, resulting in a significant deviation in $\\mathbf{x}$.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":{"source":false,"toggle":true,"caption":"See code"},"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../../styles.css"],"toc":true,"self-contained":true,"toc-depth":3,"number-sections":false,"html-math-method":"katex","embed-resources":true,"output-file":"swamping.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":{"light":"flatly","dark":"darkly"},"title":"Understanding Swamping in Numerical Computations","author":"Nathan Lunceford","preview":{"port":3000,"browser":true,"watch-inputs":true,"navigate":true},"page-layout":"full","toc-location":"right","code-summary":"Show Code","code-copy":"hover"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}