---
title: 'Bisection Method'
author: 'Nathan Lunceford'
format:
  html:
    self-contained: true
    page-layout: full
    toc: true
    toc-depth: 1
    toc-location: right
    number-sections: false
    html-math-method: katex
    embed-resources: true
    code-fold: true
    code-summary: 'Show the code'
    code-overflow: wrap
    code-copy: hover
    code-tools:
      source: false
      toggle: true
      caption: See code
engine: jupyter
preview:
  port: 3000
  browser: true
  watch-inputs: true
  navigate: true
---

**Bisection Method** is one of the simplest and most reliable numerical methods for finding a root of a continuous function $f(x) = 0$ over a closed interval $[a, b]$. The method works by repeatedly bisecting the interval and then selecting the subinterval in which the function changes sign, ensuring that a root lies within that subinterval.

## **The Bisection Method Formula**

The Bisection Method requires that the function $f(x)$ be continuous over the interval $[a, b]$, and that the function has opposite signs at the endpoints $a$ and $b$, i.e., $f(a) \cdot f(b) < 0$. This guarantees that there is at least one root in the interval by the **Intermediate Value Theorem**.

The basic idea of the method is to repeatedly bisect the interval and check the sign of $f(x)$ at the midpoint to determine the subinterval containing the root.

### **Algorithm**

1. **Initial Guess**: Choose an interval $[a_0, b_0]$ such that $f(a_0) \cdot f(b_0) < 0$.
2. **Midpoint Calculation**: Compute the midpoint $c_k = \frac{a_k + b_k}{2}$ of the interval $[a_k, b_k]$.
3. **Check the Sign**: Evaluate $f(c_k)$.
   - If $f(c_k) = 0$, then $c_k$ is the root.
   - If $f(a_k) \cdot f(c_k) < 0$, set $b_{k+1} = c_k$, and the root lies in $[a_k, c_k]$.
   - If $f(c_k) \cdot f(b_k) < 0$, set $a_{k+1} = c_k$, and the root lies in $[c_k, b_k]$.
4. **Repeat**: Continue bisecting the interval until the length of the interval is smaller than a specified tolerance $\epsilon$, or until $|f(c_k)| < \epsilon$.

The approximate root will be:

$$
x^* = \frac{a_k + b_k}{2}
$$

### **Convergence**

The Bisection Method converges **linearly**. The length of the interval halves at each iteration, ensuring that the method always converges to a solution (if one exists) within the interval.

The number of iterations $n$ required to achieve an accuracy of $\epsilon$ can be estimated by:

$$
n \geq \frac{\log \left( \frac{b_0 - a_0}{\epsilon} \right)}{\log 2}
$$

### **Example**

Let’s solve the equation $f(x) = x^3 - x - 2 = 0$ in the interval $[1, 2]$.

1. **Initial Interval**:  
   $f(1) = 1^3 - 1 - 2 = -2$  
   $f(2) = 2^3 - 2 - 2 = 4$  
   Since $f(1) \cdot f(2) < 0$, there is a root in $[1, 2]$.

2. **First Iteration**:  
   Midpoint: $c_1 = \frac{1 + 2}{2} = 1.5$  
   $f(1.5) = 1.5^3 - 1.5 - 2 = -0.125$  
   Since $f(1) \cdot f(1.5) < 0$, the root lies in $[1, 1.5]$.

3. **Second Iteration**:  
   Midpoint: $c_2 = \frac{1 + 1.5}{2} = 1.25$  
   $f(1.25) = 1.25^3 - 1.25 - 2 = -1.796875$  
   Since $f(1) \cdot f(1.25) < 0$, the root lies in $[1, 1.25]$.

4. **Further Iterations**:  
   Repeat the process until the interval width is smaller than the desired tolerance $\epsilon$.

### **General Properties of the Bisection Method**

1. **Guaranteed Convergence**: The method is guaranteed to converge to a root if $f(a) \cdot f(b) < 0$ and $f(x)$ is continuous on $[a, b]$.

2. **Rate of Convergence**: The Bisection Method has linear convergence, meaning the error decreases by a constant factor with each iteration. This makes the method slower than other methods like **Newton’s Method**, but much more reliable.

3. **Robustness**: The method is very robust as it does not require the derivative of the function and is insensitive to the initial guesses, provided the condition $f(a) \cdot f(b) < 0$ holds.

### **Applications of the Bisection Method**

- **Root Finding**: The Bisection Method is used in various fields, including physics, engineering, and mathematics, to find roots of non-linear equations.
- **Modeling and Simulation**: It is used when precise solutions are needed and the function is known to be continuous over the interval.
- **Initial Root Estimates**: The Bisection Method is often used to find a good initial approximation for more efficient methods like **Newton’s Method** or the **Secant Method**.

### **Advantages of the Bisection Method**

1. **Guaranteed Convergence**: The method always converges if the initial interval contains a root.
2. **No Derivatives Needed**: Unlike Newton’s Method, the Bisection Method does not require the computation of derivatives.
3. **Simplicity**: The method is easy to understand and implement.

### **Limitations of the Bisection Method**

1. **Slow Convergence**: The method converges linearly, which makes it slower compared to methods like Newton’s Method, which has quadratic convergence.
2. **Only One Root**: The Bisection Method only finds one root in the interval. If multiple roots exist, it cannot find them all without running the method on different intervals.

3. **Initial Interval Requirement**: The method requires an initial interval $[a, b]$ where the function changes sign, which may not always be easy to determine.

### **Conclusion**

The Bisection Method is a reliable and simple method for finding roots of continuous functions, especially when no derivative information is available. While slower than other root-finding algorithms, its guaranteed convergence and robustness make it a valuable tool in numerical analysis.
